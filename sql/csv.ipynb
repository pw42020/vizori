{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, Optional\n",
    "from typing_extensions import TypedDict\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "import pandas as pd\n",
    "import duckdb\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "path_to_csv: str = \"/Users/patrickwalsh/dev/dataly-backend/data/titanic/train.csv\"\n",
    "\n",
    "@dataclass\n",
    "class Insightly:\n",
    "    \"\"\"\n",
    "    A class to represent a connection to a DuckDB database.\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    conn : duckdb.DuckDBPyConnection\n",
    "        The DuckDB connection object.\n",
    "    \"\"\"\n",
    "    conn: duckdb.DuckDBPyConnection = field(default_factory=duckdb.connect)\n",
    "    db_name: Optional[str] = field(default=\"memory\")\n",
    "    tables: list[str] = field(default_factory=list)\n",
    "    \n",
    "    # reading the CSV file into a DuckDB table\n",
    "    def read_csv_to_duckdb(\n",
    "        self,\n",
    "        path_to_csv: str,\n",
    "        table_name: str = \"table\"\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Reads a CSV file into a DuckDB table.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        conn : duckdb.DuckDBPyConnection\n",
    "            The DuckDB connection object.\n",
    "        path_to_csv : str\n",
    "            The path to the CSV file.\n",
    "        table_name : str, optional\n",
    "            The name of the table to create in DuckDB (default is \"titanic\").\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "        \"\"\"\n",
    "        # self.db_name = table_name\n",
    "        self.conn.execute(\n",
    "            f\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS {table_name} AS\n",
    "            SELECT * FROM '{path_to_csv}'\n",
    "            \"\"\"\n",
    "        )\n",
    "        # set the list of tables for the database for later usage\n",
    "        tables_tuple = self.conn.execute(\"PRAGMA show_tables;\").fetchall()\n",
    "        print(tables_tuple)\n",
    "        self.tables = [t[0] for t in tables_tuple]\n",
    "\n",
    "    # reading the CSV file into a DuckDB table\n",
    "    def read_mysql_db(\n",
    "        self,\n",
    "        path_to_db: str,\n",
    "        db_name: str\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Reads a CSV file into a DuckDB table.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        conn : duckdb.DuckDBPyConnection\n",
    "            The DuckDB connection object.\n",
    "        path_to_db : str\n",
    "            The path to the db file.\n",
    "        db_name : str, optional\n",
    "            The name of the table to create in DuckDB (default is \"titanic\").\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "        \"\"\"\n",
    "        self.db_name = db_name\n",
    "        query: str = f\"\"\"\n",
    "            CALL sqlite_attach('{path_to_db}');\n",
    "            ATTACH '{path_to_db}' AS {db_name} (TYPE sqlite);\n",
    "        \"\"\"\n",
    "        print(query)\n",
    "        self.conn.execute(query)\n",
    "\n",
    "        # set the list of tables for the database for later usage\n",
    "        tables_tuple = self.conn.execute(\"PRAGMA show_tables;\").fetchall()\n",
    "        self.tables = [t[0] for t in tables_tuple]\n",
    "\n",
    "    def retrieve_table(\n",
    "        self,\n",
    "        table_name: str\n",
    "    ) -> duckdb.DuckDBPyRelation:\n",
    "        \"\"\"\n",
    "        Retrieves a DuckDB table as a relation.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        conn : duckdb.DuckDBPyConnection\n",
    "            The DuckDB connection object.\n",
    "        table_name : str, optional\n",
    "            The name of the table to retrieve (default is \"titanic\").\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        duckdb.DuckDBPyRelation\n",
    "            The relation representing the DuckDB table.\n",
    "        \"\"\"\n",
    "        return self.conn.table(table_name)\n",
    "\n",
    "    # get the schema using duckdb\n",
    "    def get_schema(self, table_name: Optional[str] = None) -> Dict[str, Any]:\n",
    "        # get the schema with each of the table names\n",
    "        tables = [table_name] if table_name is not None else self.tables\n",
    "        schemas = {}\n",
    "\n",
    "        for table in tables:\n",
    "            # Fetch column info\n",
    "            info = self.conn.execute(f\"PRAGMA table_info('{self.db_name}.{table}')\").fetchall()\n",
    "            \n",
    "            # Format into a string\n",
    "            schema_string = \", \".join(f\"{col[1]} {col[2]}\" for col in info)\n",
    "            \n",
    "            schemas[table] = schema_string\n",
    "        \n",
    "        schema = \"\"\n",
    "        for key, value in schemas.items():\n",
    "            schema += \"Table name: \"+key+\"\\n\"\n",
    "            schema += value + \"\\n\"\n",
    "        \n",
    "        return str(schema)\n",
    "\n",
    "    def add_df_to_duckdb(\n",
    "        self,\n",
    "        df: pd.DataFrame,\n",
    "        table_name: str\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Inserts a DataFrame into a DuckDB table.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        conn : duckdb.DuckDBPyConnection\n",
    "            The DuckDB connection object.\n",
    "        df : pd.DataFrame\n",
    "            The DataFrame to insert.\n",
    "        table_name : str\n",
    "            The name of the table to insert into.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "        \"\"\"\n",
    "        # Create the table if it doesn't exist\n",
    "        self.conn.execute(f\"CREATE TABLE IF NOT EXISTS {table_name} AS SELECT * FROM df LIMIT 0\")\n",
    "        \n",
    "        # Insert the DataFrame into the table\n",
    "        self.conn.execute(f\"INSERT INTO {table_name} SELECT * FROM df\")\n",
    "        \n",
    "        # Commit the changes\n",
    "        self.conn.commit()\n",
    "    \n",
    "    def execute_query(\n",
    "        self,\n",
    "        query: str\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Executes a SQL query on the DuckDB connection.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        query : str\n",
    "            The SQL query to execute\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        pd.DataFrame\n",
    "            The result of the executed query as a relation.\n",
    "        \"\"\"\n",
    "        executed_query = self.conn.sql(query)\n",
    "        # commit\n",
    "        self.conn.commit()\n",
    "        return executed_query\n",
    "    \n",
    "# Example usage\n",
    "insightly = Insightly()\n",
    "insightly.read_csv_to_duckdb(path_to_csv, \"titanic\")\n",
    "# table = insightly.retrieve_table(\"db.foods\")\n",
    "# print(table.df())\n",
    "schema = insightly.get_schema()\n",
    "print(f\"schema: {schema}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "from pydantic import Field, BaseModel\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables.config import RunnableConfig\n",
    "\n",
    "class PlotType(str, Enum):\n",
    "    \"\"\"Plot type for the visualization of the data.\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    BAR : str\n",
    "        Bar plot.\n",
    "    SCATTER : str\n",
    "        Scatter plot.\n",
    "    LINE : str\n",
    "        Line plot.\n",
    "    HISTOGRAM : str\n",
    "        Histogram plot.\n",
    "    PIE : str\n",
    "        Pie plot.\n",
    "    HEATMAP : str\n",
    "        Heatmap plot.\n",
    "    \"\"\"\n",
    "    SCATTER = \"SCATTER\"\n",
    "    BAR = \"BAR\"\n",
    "    # LINE = \"LINE\"\n",
    "    # HISTOGRAM = \"HISTOGRAM\"\n",
    "    # PIE = \"PIE\"\n",
    "    # HEATMAP = \"HEATMAP\"\n",
    "\n",
    "class SqlQueryInfo(TypedDict):\n",
    "    \"\"\"Information regarding the SQL query performed on the request.\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    sql_query : str\n",
    "        The SQL query that was executed.\n",
    "    query_result : str\n",
    "        The result of the SQL query.\n",
    "    table_name : str\n",
    "        The name of the table that was queried.\n",
    "    query_rows : list\n",
    "        The rows returned from the SQL query.\n",
    "    sql_error : bool\n",
    "        Indicates whether there was an error in the SQL query.\n",
    "    \"\"\"\n",
    "    sql_query: str\n",
    "    query_result: str\n",
    "    table_name: str\n",
    "    query_rows: list\n",
    "    sql_error: bool\n",
    "\n",
    "class PlotQueryInfo(TypedDict):\n",
    "    \"\"\"Plot query information for the visualization of the data.\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    plot_query: str\n",
    "        The SQL query that was executed\n",
    "    columns: list\n",
    "        The columns that were used in the plot\n",
    "    result: str\n",
    "        The result of the SQL query\n",
    "    \"\"\"\n",
    "    plot_type: str\n",
    "    columns: list[str]\n",
    "    result: str\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    \"\"\"Agent state for the SQL query and plot information.\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    question: str\n",
    "        The question that was asked.\n",
    "    meant_as_query: bool\n",
    "        Indicates whether the question was meant as a query or to be plotted.\n",
    "    sql_query_info: SqlQueryInfo\n",
    "        Information regarding the SQL query performed on the request.\n",
    "    plot_query_info: PlotQueryInfo\n",
    "        Information regarding the plot query performed on the request.\n",
    "    attempts: int\n",
    "        The number of attempts made to answer the question.\n",
    "    relevance: str\n",
    "        Indicates whether the question is related to the database schema.\n",
    "    \"\"\"\n",
    "    question: str\n",
    "    meant_as_query: bool\n",
    "    sql_query_info: Optional[SqlQueryInfo] = None\n",
    "    plot_query_info: Optional[PlotQueryInfo] = None\n",
    "    attempts: int\n",
    "    relevance: str\n",
    "\n",
    "# this is made to be used with the LangChain framework and is a prompt\n",
    "# to ensure that the answer given by the LLM is structured\n",
    "class CheckRelevance(BaseModel):\n",
    "    \"\"\"Checks the relevance of the question to the database schema.\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    relevance: str\n",
    "        Indicates whether the question is related to the database schema.\n",
    "    \"\"\"\n",
    "    relevance: str = Field(\n",
    "        description=\"Indicates whether the question is related to the database schema. 'relevant' or 'not_relevant'.\"\n",
    "    )\n",
    "\n",
    "def check_relevance(state: AgentState, config: RunnableConfig) -> AgentState:\n",
    "    \"\"\"\n",
    "    Check the relevance of the question to the database schema.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    state : AgentState\n",
    "        The current state of the agent.\n",
    "    config : RunnableConfig\n",
    "        The configuration for the runnable.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    AgentState\n",
    "        The updated state of the agent with the relevance information.\n",
    "    \"\"\"\n",
    "    question = state[\"question\"]\n",
    "    schema = insightly.get_schema()\n",
    "    print(f\"Checking relevance of the question: {question}\")\n",
    "    system = \"\"\"You are an assistant that determines whether a given question is related to the following database schema.\n",
    "\n",
    "Schema:\n",
    "{schema}\n",
    "\n",
    "Respond with only \"relevant\" or \"not_relevant\".\n",
    "\"\"\".format(schema=schema)\n",
    "    human = f\"Question: {question}\"\n",
    "    check_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", system),\n",
    "            (\"human\", human),\n",
    "        ]\n",
    "    )\n",
    "    llm = ChatOpenAI(temperature=0)\n",
    "    structured_llm = llm.with_structured_output(CheckRelevance)\n",
    "    relevance_checker = check_prompt | structured_llm\n",
    "    relevance = relevance_checker.invoke({})\n",
    "    state[\"relevance\"] = relevance.relevance\n",
    "    print(f\"Relevance determined: {state['relevance']}\")\n",
    "    return state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "\n",
    "class QueryType(str, Enum):\n",
    "    \"\"\"Query type for the question.\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    SQL : str\n",
    "        Indicates that the question requires an SQL query.\n",
    "    SCATTER : str\n",
    "        Indicates that the question requires a scatter plot.\n",
    "    BAR : str\n",
    "        Indicates that the question requires a bar plot.\n",
    "    \"\"\"\n",
    "    SQL = \"sql\"\n",
    "    SCATTER = \"scatter\"\n",
    "    BAR = \"bar\"\n",
    "\n",
    "class CheckIfSQLOrPlot(BaseModel):\n",
    "    \"\"\"Check if the question is meant as an SQL query or a plot.\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    meant_as_query : QueryType\n",
    "        Indicates whether the question requires an SQL query or a plot.\n",
    "    type_of_plot : PlotType\n",
    "        The type of plot to be generated if the question requires a plot.\n",
    "    \"\"\"\n",
    "    meant_as_query: QueryType = Field(\n",
    "        description=\"Indicates whether the question requires an SQL query or a plot.\"\n",
    "    )\n",
    "    type_of_plot: PlotType = Field(\n",
    "        description=\"The type of plot to be generated if the question requires a plot.\"\n",
    "    )\n",
    "\n",
    "def check_if_sql_or_plot(state: AgentState, config: RunnableConfig) -> AgentState:\n",
    "    \"\"\"Check if the question is meant as an SQL query or a plot.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    state : AgentState  \n",
    "        The state of the agent containing the question and other information.\n",
    "    config : RunnableConfig\n",
    "        The configuration for the runnable.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    AgentState\n",
    "        The updated state of the agent with the determined type of query.\n",
    "    \"\"\"\n",
    "    question = state[\"question\"]\n",
    "    print(f\"Checking if the question requires an SQL query or a plot: {question}\")\n",
    "    schema = insightly.get_schema()\n",
    "    system = \"\"\"\n",
    "You are an assistant that determines whether a given question requires an SQL query or a plot based on the following schema:\n",
    "{schema}\n",
    "\n",
    "Respond with 'sql' if the question is related to data retrieval or manipulation that can be expressed in SQL.\n",
    "If the question is related to data visualization, choose one of the following plot types with no explanation: {plot_types}.\n",
    "\"\"\".format(schema=schema, plot_types=\", \".join([member.value for member in PlotType]))\n",
    "    # If the question is related to data visualization, provide the type of plot as one of the following with no explanation: , BAR, LINE, HISTOGRAM, PIE, HEATMAP.\n",
    "    human = f\"Question: {question}\"\n",
    "    check_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", system),\n",
    "            (\"human\", human),\n",
    "        ]\n",
    "    )\n",
    "    llm = ChatOpenAI(temperature=0)\n",
    "    structured_llm = llm.with_structured_output(CheckIfSQLOrPlot)\n",
    "    type_checker = check_prompt | structured_llm\n",
    "    result = type_checker.invoke({})\n",
    "    state[\"meant_as_query\"] = result.meant_as_query == QueryType.SQL\n",
    "    print(\"MEANT AS QUERY: \", state[\"meant_as_query\"])\n",
    "    # generate a random table name for the SQL query and the typed dictionaries\n",
    "    state[\"sql_query_info\"] = SqlQueryInfo(\n",
    "        sql_query=\"\",\n",
    "        query_result=\"\",\n",
    "        table_name=f'transformation_{randint(0, 10000)}',\n",
    "        query_rows=[]\n",
    "    )\n",
    "    state[\"plot_query_info\"] = PlotQueryInfo(\n",
    "        plot_type=result.type_of_plot.value,\n",
    "        query_result=\"\",\n",
    "        query_rows=[]\n",
    "    )\n",
    "    # check if the meant_as_query is a boolean\n",
    "    assert state[\"meant_as_query\"] in [True, False], \"Meant as query should be a boolean\"\n",
    "    print(f\"Determined type: {state['meant_as_query']}\")\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvertToSQL(BaseModel):\n",
    "    sql_query: str = Field(\n",
    "        description=\"The SQL query generated from the natural language question.\"\n",
    "    )\n",
    "\n",
    "def convert_nl_to_sql(state: AgentState, config: RunnableConfig):\n",
    "    print(\"Convert natural language to SQL\")\n",
    "    question = state[\"question\"]\n",
    "    schema = insightly.get_schema()\n",
    "    print(f\"Converting question to SQL: {question}\")\n",
    "    system = \"\"\"You are an assistant that converts natural language questions into SQL queries based on the following schema:\n",
    "database name: {db_name}\n",
    "All tables should begin with the database name (i.e. {db_name}.foods).\n",
    "{schema}\n",
    "\n",
    "Provide only the SQL query without any explanations. Alias columns appropriately to match the expected keys in the result.\n",
    "\n",
    "For example, alias 'food.name' as 'food_name' and 'food.price' as 'price'.\n",
    "\"\"\".format(schema=schema, db_name=insightly.db_name)\n",
    "    convert_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", system),\n",
    "            (\"human\", f\"Question: {question}\"),\n",
    "        ]\n",
    "    )\n",
    "    llm = ChatOpenAI(temperature=0)\n",
    "    structured_llm = llm.with_structured_output(ConvertToSQL)\n",
    "    sql_generator = convert_prompt | structured_llm\n",
    "    result = sql_generator.invoke({})\n",
    "    state[\"sql_query_info\"][\"sql_query\"] = result.sql_query\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_sql(state: AgentState):\n",
    "    sql_query = state[\"sql_query_info\"][\"sql_query\"].strip()\n",
    "    print(f\"Executing SQL query: {sql_query}\")\n",
    "    try:\n",
    "        result: duckdb.DuckDBPyRelation = insightly.execute_query(sql_query)\n",
    "        if sql_query.lower().startswith(\"select\"):\n",
    "            dataframe = result.df()\n",
    "            state[\"sql_query_info\"][\"query_result\"] = dataframe\n",
    "            print(\"SUCCESSFUL EXECUTION OF SQL QUERY\")\n",
    "            # duckdb add the new df to the database\n",
    "            insightly.add_df_to_duckdb(dataframe, state[\"sql_query_info\"][\"table_name\"])\n",
    "            state[\"sql_query_info\"][\"sql_error\"] = False\n",
    "            print(\"SQL SELECT query executed successfully.\")\n",
    "        else:\n",
    "            state[\"sql_query_info\"][\"query_result\"] = \"The action has been successfully completed.\"\n",
    "            state[\"sql_query_info\"][\"sql_error\"] = False\n",
    "            print(\"SQL command executed successfully.\")\n",
    "    except Exception as e:\n",
    "        state[\"sql_query_info\"][\"query_result\"] = f\"Error executing SQL query: {str(e)}\"\n",
    "        state[\"sql_query_info\"][\"sql_error\"] = True\n",
    "        print(f\"Error executing SQL query: {str(e)}\")\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "def generate_scatter_plot(df: pd.DataFrame, columns: list[str]):\n",
    "    # columns = state.get(\"columns\", [])\n",
    "    if len(columns) != 2:\n",
    "        raise ValueError(\"Scatter plot requires exactly two columns.\")\n",
    "    \n",
    "    # Generate a scatter plot (this is a placeholder, actual plotting code would go here)\n",
    "    return px.scatter(df, x=columns[0], y=columns[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_bar_plot(df: pd.DataFrame, columns: list[str]):\n",
    "    # columns = state.get(\"columns\", [])\n",
    "    # if len(columns) != 2:\n",
    "    #     raise ValueError(\"Bar plot requires exactly one column.\")\n",
    "    print(\"GENERATE BAR PLOT\")\n",
    "    print(df, type(df))\n",
    "    \n",
    "    # Generate a bar plot (this is a placeholder, actual plotting code would go here)\n",
    "    return px.bar(df, x=columns[0], y=columns[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Columns(BaseModel):\n",
    "    columns: list[str] = Field(\n",
    "        description=\"The columns to be used in the scatter plot.\"\n",
    "    )\n",
    "\n",
    "def get_columns(state: AgentState, config: RunnableConfig):\n",
    "    question = state[\"question\"]\n",
    "    schema = insightly.get_schema(table_name=state['sql_query_info']['table_name'])\n",
    "    print(f\"Getting columns: {question}\")\n",
    "    print(\"current schema: \", schema)\n",
    "    system = \"\"\"You are an assistant that chooses the appropriate columns for a scatter plot based on the following schema:\n",
    "\n",
    "{schema}\n",
    "\n",
    "Provide only the columns to be used in the scatter plot without any explanations.\n",
    "The columns should be suitable for a scatter plot, typically two numerical columns.\n",
    "Only return the names of the columns with no SQL, in the order they should be used in the plot (i.e. x1, y1, x2, y2).\n",
    "\"\"\".format(schema=schema)\n",
    "    convert_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", system),\n",
    "            (\"human\", \"Question: {question}\"),\n",
    "        ]\n",
    "    )\n",
    "    llm = ChatOpenAI(temperature=0)\n",
    "    structured_llm = llm.with_structured_output(Columns)\n",
    "    sql_generator = convert_prompt | structured_llm\n",
    "    result = sql_generator.invoke({\"question\": question})\n",
    "    print(f\"Generated columns for plot: {result.columns}\")\n",
    "    state[\"plot_query_info\"][\"columns\"] = result.columns\n",
    "    # create a plot dependent on the type of plot type passed earlier\n",
    "    if state[\"plot_query_info\"][\"plot_type\"] == PlotType.SCATTER:\n",
    "        state[\"plot_query_info\"][\"result\"] = generate_scatter_plot(state[\"sql_query_info\"][\"query_result\"],\n",
    "                                                                   state[\"plot_query_info\"][\"columns\"])\n",
    "    elif state[\"plot_query_info\"][\"plot_type\"] == PlotType.BAR:\n",
    "        state[\"plot_query_info\"][\"result\"] = generate_bar_plot(state[\"sql_query_info\"][\"query_result\"],\n",
    "                                                               state[\"plot_query_info\"][\"columns\"])\n",
    "    print(f\"Selected columns for scatter plot: {state['plot_query_info']['columns']}\")\n",
    "    return state\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "def generate_funny_response(state: AgentState):\n",
    "    print(\"Generating a funny response for an unrelated question.\")\n",
    "    system = \"\"\"You are a charming and funny assistant who responds in a playful manner.\n",
    "    \"\"\"\n",
    "    human_message = \"I can't help with that unfortunately!\"\n",
    "    funny_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", system),\n",
    "            (\"human\", human_message),\n",
    "        ]\n",
    "    )\n",
    "    llm = ChatOpenAI(temperature=0.7)\n",
    "    funny_response = funny_prompt | llm | StrOutputParser()\n",
    "    message = funny_response.invoke({})\n",
    "    # initialize the SQL query info\n",
    "    state[\"sql_query_info\"] = SqlQueryInfo(\n",
    "        sql_query=\"\",\n",
    "        query_result=\"\",\n",
    "        query_rows=[],\n",
    "        sql_error=False\n",
    "    )\n",
    "    state[\"sql_query_info\"][\"query_result\"] = message\n",
    "    print(\"Generated funny response.\")\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RewrittenQuestion(BaseModel):\n",
    "    question: str = Field(description=\"The rewritten question.\")\n",
    "\n",
    "def regenerate_query(state: AgentState):\n",
    "    question = state[\"question\"]\n",
    "    print(\"Regenerating the SQL query by rewriting the question.\")\n",
    "    system = \"\"\"You are an assistant that reformulates an original question to enable more precise SQL queries. Ensure that all necessary details, such as table joins, are preserved to retrieve complete and accurate data.\n",
    "    \"\"\"\n",
    "    rewrite_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", system),\n",
    "            (\n",
    "                \"human\",\n",
    "                f\"Original Question: {question}\\nReformulate the question to enable more precise SQL queries, ensuring all necessary details are preserved.\",\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "    llm = ChatOpenAI(temperature=0)\n",
    "    structured_llm = llm.with_structured_output(RewrittenQuestion)\n",
    "    rewriter = rewrite_prompt | structured_llm\n",
    "    rewritten = rewriter.invoke({})\n",
    "    state[\"question\"] = rewritten.question\n",
    "    state[\"attempts\"] += 1\n",
    "    print(f\"Rewritten question: {state['question']}\")\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HumanResponse(BaseModel):\n",
    "    response: str = Field(description=\"The human response to the question.\")\n",
    "\n",
    "def human_response(state: AgentState, config: RunnableConfig):\n",
    "    question = state[\"question\"]\n",
    "    answer: str = state[\"sql_query_info\"][\"query_result\"]\n",
    "    print(f\"Waiting for human response to the question: {question}\")\n",
    "    system = \"\"\"You are an assistant that retrieves the result of a question asked\n",
    "by a human and provides a normal response based on the question. The answer is {answer}\"\"\".format(answer=answer)\n",
    "    human_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", system),\n",
    "            (\"human\", f\"Question: {question}\\nPlease provide your response.\"),\n",
    "        ]\n",
    "    )\n",
    "    llm = ChatOpenAI(temperature=0)\n",
    "    structured_llm = llm.with_structured_output(HumanResponse)\n",
    "    human_responder = human_prompt | structured_llm\n",
    "    response = human_responder.invoke({})\n",
    "    state[\"question\"] = response.response\n",
    "    print(f\"Received human response: {state['question']}\")\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "class State(str, Enum):\n",
    "    CHECK_RELEVANCE: str = \"check_relevance\"\n",
    "    CHECK_IF_SQL_OR_PLOT: str = \"check_if_sql_or_plot\"\n",
    "    CONVERT_NL_TO_SQL: str = \"convert_nl_to_sql\"\n",
    "    GET_COLUMNS: str = \"get_columns\"\n",
    "    GENERATE_SCATTER_PLOT: str = \"generate_scatter_plot\"\n",
    "    GENERATE_FUNNY_RESPONSE: str = \"generate_funny_response\"\n",
    "    REGENERATE_QUERY: str = \"regenerate_query\"\n",
    "    EXECUTE_SQL: str = \"execute_sql\"\n",
    "    END_MAX_ITERATIONS: str = \"end_max_iterations\"\n",
    "    CHECK_IF_ERROR: str = \"check_if_error\"\n",
    "    GENERATE_SUCCESS_RESPONSE: str = \"generate_human_response\"\n",
    "\n",
    "# ROUTERS\n",
    "def end_max_iterations(state: AgentState):\n",
    "    state[\"query_result\"] = \"Please try again.\"\n",
    "    print(\"Maximum attempts reached. Ending the workflow.\")\n",
    "    return state\n",
    "\n",
    "def relevance_router(state: AgentState) -> State:\n",
    "    if state[\"relevance\"] == \"relevant\":\n",
    "        return State.CHECK_IF_SQL_OR_PLOT\n",
    "    else:\n",
    "        return State.GENERATE_FUNNY_RESPONSE\n",
    "    \n",
    "def type_router(state: AgentState) -> State:\n",
    "    # NOTE: add a condition to see if it would be more useful to see\n",
    "    # a dataframe instead of a simple English response\n",
    "    if state[\"meant_as_query\"]:\n",
    "        return State.CONVERT_NL_TO_SQL\n",
    "    else:\n",
    "        return State.GET_COLUMNS\n",
    "    \n",
    "def check_if_error(state: AgentState):\n",
    "    if not state.get(\"sql_error\", False):\n",
    "        # if the SQL query was executed, redirect to get columns if looking\n",
    "        # to plot, and to generate a human response if looking to answer\n",
    "        # the question with English\n",
    "        if state[\"meant_as_query\"]:\n",
    "            return State.GENERATE_SUCCESS_RESPONSE\n",
    "        return State.GET_COLUMNS\n",
    "    else:\n",
    "        return State.REGENERATE_QUERY\n",
    "    \n",
    "def check_attempts_router(state: AgentState):\n",
    "    if state[\"attempts\"] < 3:\n",
    "        return State.CONVERT_NL_TO_SQL\n",
    "    else:\n",
    "        return State.END_MAX_ITERATIONS\n",
    "    \n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# relevancy checks at the beginning to ensure question is relevant and can be answered\n",
    "workflow.add_node(State.CHECK_RELEVANCE, check_relevance)\n",
    "workflow.add_node(State.CONVERT_NL_TO_SQL, convert_nl_to_sql)\n",
    "workflow.add_node(State.EXECUTE_SQL, execute_sql)\n",
    "workflow.add_node(State.GENERATE_SUCCESS_RESPONSE, human_response)\n",
    "\n",
    "# if the question is relevant, make a query. If not, generate a funny response\n",
    "workflow.add_conditional_edges(State.CHECK_RELEVANCE, relevance_router)\n",
    "\n",
    "# checking if the question is meant to be answered with SQL statement or a plot\n",
    "workflow.add_node(State.CHECK_IF_SQL_OR_PLOT, check_if_sql_or_plot)\n",
    "workflow.add_edge(State.CHECK_IF_SQL_OR_PLOT, State.CONVERT_NL_TO_SQL)\n",
    "\n",
    "# # adding conditional edge to go different directions based on query type\n",
    "\n",
    "# if the question is meant to be answered with SQL,\n",
    "# convert the natural language question to SQL query\n",
    "workflow.add_edge(State.CONVERT_NL_TO_SQL, State.EXECUTE_SQL)\n",
    "\n",
    "# once SQL has been executed, first check if there was an error\n",
    "workflow.add_conditional_edges(State.EXECUTE_SQL, check_if_error)\n",
    "\n",
    "# regenerate attempt if you still have attempts left -- already errored by this point\n",
    "workflow.add_conditional_edges(State.REGENERATE_QUERY, check_attempts_router)\n",
    "\n",
    "# if the question is relevant but the SQL query is not executed successfully,\n",
    "# regenerate the query by rewriting the question\n",
    "workflow.add_node(State.REGENERATE_QUERY, regenerate_query)\n",
    "workflow.add_edge(State.REGENERATE_QUERY, State.CONVERT_NL_TO_SQL)\n",
    "workflow.add_node(State.END_MAX_ITERATIONS, end_max_iterations)\n",
    "workflow.add_edge(State.END_MAX_ITERATIONS, END)\n",
    "\n",
    "# if the question is meant to be answered with a plot,\n",
    "# get the columns for the scatter plot\n",
    "workflow.add_node(State.GET_COLUMNS, get_columns)\n",
    "# workflow.add_node(State.GENERATE_SCATTER_PLOT, generate_scatter_plot)\n",
    "# workflow.add_edge(State.GET_COLUMNS, State.GENERATE_SCATTER_PLOT)\n",
    "workflow.add_edge(State.GET_COLUMNS, END)\n",
    "\n",
    "# if the question is not relevant, generate a funny response\n",
    "workflow.add_node(State.GENERATE_FUNNY_RESPONSE, generate_funny_response)\n",
    "workflow.add_edge(State.GENERATE_FUNNY_RESPONSE, END)\n",
    "\n",
    "workflow.set_entry_point(State.CHECK_RELEVANCE)\n",
    "\n",
    "app = workflow.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "from langchain_core.runnables.graph import MermaidDrawMethod\n",
    "\n",
    "display(\n",
    "    Image(\n",
    "        app.get_graph().draw_mermaid_png(\n",
    "            draw_method=MermaidDrawMethod.API,\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Create a bar plot that shows the number of passengers, grouped by 10 year age buckets.\"\n",
    "result: dict[str, dict[str, Any]] = app.invoke({\"question\": question, \"attempts\": 0}, config={})\n",
    "if result.get(\"meant_as_query\", False):\n",
    "    # if the SQL query was executed successfully, print the result\n",
    "    print(\"Result:\", result[\"sql_query_info\"][\"query_result\"])\n",
    "else:\n",
    "    # if the plot was generated successfully, show the plot that was returned\n",
    "    result[\"plot_query_info\"][\"result\"].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "print(result[\"sql_query_info\"][\"query_result\"])\n",
    "\n",
    "px.bar(result[\"sql_query_info\"][\"query_result\"], x=\"age_group\", y=\"num_passengers\").show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
