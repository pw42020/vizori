{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('titanic',)]\n",
      "schema: Table name: titanic\n",
      "PassengerId BIGINT, Survived BIGINT, Pclass BIGINT, Name VARCHAR, Sex VARCHAR, Age DOUBLE, SibSp BIGINT, Parch BIGINT, Ticket VARCHAR, Fare DOUBLE, Cabin VARCHAR, Embarked VARCHAR\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from typing import Any, Dict, Optional\n",
    "from typing_extensions import TypedDict\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "import pandas as pd\n",
    "import duckdb\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "path_to_csv: str = \"/Users/patrickwalsh/dev/dataly-backend/data/titanic/train.csv\"\n",
    "\n",
    "@dataclass\n",
    "class Insightly:\n",
    "    \"\"\"\n",
    "    A class to represent a connection to a DuckDB database.\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    conn : duckdb.DuckDBPyConnection\n",
    "        The DuckDB connection object.\n",
    "    \"\"\"\n",
    "    conn: duckdb.DuckDBPyConnection = field(default_factory=duckdb.connect)\n",
    "    db_name: Optional[str] = field(default=\"memory\")\n",
    "    tables: list[str] = field(default_factory=list)\n",
    "    \n",
    "    # reading the CSV file into a DuckDB table\n",
    "    def read_csv_to_duckdb(\n",
    "        self,\n",
    "        path_to_csv: str,\n",
    "        table_name: str = \"titanic\"\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Reads a CSV file into a DuckDB table.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        conn : duckdb.DuckDBPyConnection\n",
    "            The DuckDB connection object.\n",
    "        path_to_csv : str\n",
    "            The path to the CSV file.\n",
    "        table_name : str, optional\n",
    "            The name of the table to create in DuckDB (default is \"titanic\").\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "        \"\"\"\n",
    "        # self.db_name = table_name\n",
    "        self.conn.execute(\n",
    "            f\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS {table_name} AS\n",
    "            SELECT * FROM '{path_to_csv}'\n",
    "            \"\"\"\n",
    "        )\n",
    "        # set the list of tables for the database for later usage\n",
    "        tables_tuple = self.conn.execute(\"PRAGMA show_tables;\").fetchall()\n",
    "        print(tables_tuple)\n",
    "        self.tables = [t[0] for t in tables_tuple]\n",
    "\n",
    "    # reading the CSV file into a DuckDB table\n",
    "    def read_mysql_db(\n",
    "        self,\n",
    "        path_to_db: str,\n",
    "        db_name: str\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Reads a CSV file into a DuckDB table.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        conn : duckdb.DuckDBPyConnection\n",
    "            The DuckDB connection object.\n",
    "        path_to_db : str\n",
    "            The path to the db file.\n",
    "        db_name : str, optional\n",
    "            The name of the table to create in DuckDB (default is \"titanic\").\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "        \"\"\"\n",
    "        self.db_name = db_name\n",
    "        query: str = f\"\"\"\n",
    "            CALL sqlite_attach('{path_to_db}');\n",
    "            ATTACH '{path_to_db}' AS {db_name} (TYPE sqlite);\n",
    "        \"\"\"\n",
    "        print(query)\n",
    "        self.conn.execute(query)\n",
    "\n",
    "        # set the list of tables for the database for later usage\n",
    "        tables_tuple = self.conn.execute(\"PRAGMA show_tables;\").fetchall()\n",
    "        self.tables = [t[0] for t in tables_tuple]\n",
    "\n",
    "    def retrieve_table(\n",
    "        self,\n",
    "        table_name: str\n",
    "    ) -> duckdb.DuckDBPyRelation:\n",
    "        \"\"\"\n",
    "        Retrieves a DuckDB table as a relation.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        conn : duckdb.DuckDBPyConnection\n",
    "            The DuckDB connection object.\n",
    "        table_name : str, optional\n",
    "            The name of the table to retrieve (default is \"titanic\").\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        duckdb.DuckDBPyRelation\n",
    "            The relation representing the DuckDB table.\n",
    "        \"\"\"\n",
    "        return self.conn.table(table_name)\n",
    "\n",
    "    # get the schema using duckdb\n",
    "    def get_schema(self, table_name: Optional[str] = None) -> Dict[str, Any]:\n",
    "        # get the schema with each of the table names\n",
    "        tables = [table_name] if table_name is not None else self.tables\n",
    "        schemas = {}\n",
    "\n",
    "        for table in tables:\n",
    "            # Fetch column info\n",
    "            info = self.conn.execute(f\"PRAGMA table_info('{self.db_name}.{table}')\").fetchall()\n",
    "            \n",
    "            # Format into a string\n",
    "            schema_string = \", \".join(f\"{col[1]} {col[2]}\" for col in info)\n",
    "            \n",
    "            schemas[table] = schema_string\n",
    "        \n",
    "        schema = \"\"\n",
    "        for key, value in schemas.items():\n",
    "            schema += \"Table name: \"+key+\"\\n\"\n",
    "            schema += value + \"\\n\"\n",
    "        \n",
    "        return str(schema)\n",
    "\n",
    "    def add_df_to_duckdb(\n",
    "        self,\n",
    "        df: pd.DataFrame,\n",
    "        table_name: str\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Inserts a DataFrame into a DuckDB table.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        conn : duckdb.DuckDBPyConnection\n",
    "            The DuckDB connection object.\n",
    "        df : pd.DataFrame\n",
    "            The DataFrame to insert.\n",
    "        table_name : str\n",
    "            The name of the table to insert into.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "        \"\"\"\n",
    "        # Create the table if it doesn't exist\n",
    "        self.conn.execute(f\"CREATE TABLE IF NOT EXISTS {table_name} AS SELECT * FROM df LIMIT 0\")\n",
    "        \n",
    "        # Insert the DataFrame into the table\n",
    "        self.conn.execute(f\"INSERT INTO {table_name} SELECT * FROM df\")\n",
    "        \n",
    "        # Commit the changes\n",
    "        self.conn.commit()\n",
    "    \n",
    "    def execute_query(\n",
    "        self,\n",
    "        query: str\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Executes a SQL query on the DuckDB connection.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        query : str\n",
    "            The SQL query to execute\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        pd.DataFrame\n",
    "            The result of the executed query as a relation.\n",
    "        \"\"\"\n",
    "        executed_query = self.conn.sql(query)\n",
    "        # commit\n",
    "        self.conn.commit()\n",
    "        return executed_query\n",
    "    \n",
    "# Example usage\n",
    "insightly = Insightly()\n",
    "insightly.read_csv_to_duckdb(path_to_csv, \"titanic\")\n",
    "# table = insightly.retrieve_table(\"db.foods\")\n",
    "# print(table.df())\n",
    "schema = insightly.get_schema()\n",
    "print(f\"schema: {schema}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "from pydantic import Field, BaseModel\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables.config import RunnableConfig\n",
    "\n",
    "class PlotType(str, Enum):\n",
    "    \"\"\"Plot type for the visualization of the data.\"\"\"\n",
    "    SCATTER = \"SCATTER\"\n",
    "    BAR = \"BAR\"\n",
    "    # LINE = \"LINE\"\n",
    "    # HISTOGRAM = \"HISTOGRAM\"\n",
    "    # PIE = \"PIE\"\n",
    "    # HEATMAP = \"HEATMAP\"\n",
    "\n",
    "class SqlQueryInfo(TypedDict):\n",
    "    sql_query: str\n",
    "    query_result: str\n",
    "    table_name: str\n",
    "    query_rows: list\n",
    "    sql_error: bool\n",
    "\n",
    "class PlotQueryInfo(TypedDict):\n",
    "    plot_type: str\n",
    "    columns: list[str]\n",
    "    result: str\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    question: str\n",
    "    meant_as_query: bool\n",
    "    sql_query_info: Optional[SqlQueryInfo] = None\n",
    "    plot_query_info: Optional[PlotQueryInfo] = None\n",
    "    attempts: int\n",
    "    relevance: str\n",
    "\n",
    "# this is made to be used with the LangChain framework and is a prompt\n",
    "# to ensure that the answer given by the LLM is structured\n",
    "class CheckRelevance(BaseModel):\n",
    "    relevance: str = Field(\n",
    "        description=\"Indicates whether the question is related to the database schema. 'relevant' or 'not_relevant'.\"\n",
    "    )\n",
    "\n",
    "def check_relevance(state: AgentState, config: RunnableConfig):\n",
    "    question = state[\"question\"]\n",
    "    schema = insightly.get_schema()\n",
    "    print(f\"Checking relevance of the question: {question}\")\n",
    "    system = \"\"\"You are an assistant that determines whether a given question is related to the following database schema.\n",
    "\n",
    "Schema:\n",
    "{schema}\n",
    "\n",
    "Respond with only \"relevant\" or \"not_relevant\".\n",
    "\"\"\".format(schema=schema)\n",
    "    human = f\"Question: {question}\"\n",
    "    check_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", system),\n",
    "            (\"human\", human),\n",
    "        ]\n",
    "    )\n",
    "    llm = ChatOpenAI(temperature=0)\n",
    "    structured_llm = llm.with_structured_output(CheckRelevance)\n",
    "    relevance_checker = check_prompt | structured_llm\n",
    "    relevance = relevance_checker.invoke({})\n",
    "    state[\"relevance\"] = relevance.relevance\n",
    "    print(f\"Relevance determined: {state['relevance']}\")\n",
    "    return state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "\n",
    "class QueryType(str, Enum):\n",
    "    SQL = \"sql\"\n",
    "    SCATTER = \"scatter\"\n",
    "    BAR = \"bar\"\n",
    "\n",
    "class CheckIfSQLOrPlot(BaseModel):\n",
    "    meant_as_query: QueryType = Field(\n",
    "        description=\"Indicates whether the question requires an SQL query or a plot.\"\n",
    "    )\n",
    "    type_of_plot: PlotType = Field(\n",
    "        description=\"The type of plot to be generated if the question requires a plot.\"\n",
    "    )\n",
    "\n",
    "def check_if_sql_or_plot(state: AgentState, config: RunnableConfig):\n",
    "    question = state[\"question\"]\n",
    "    print(f\"Checking if the question requires an SQL query or a plot: {question}\")\n",
    "    schema = insightly.get_schema()\n",
    "    system = \"\"\"\n",
    "You are an assistant that determines whether a given question requires an SQL query or a plot based on the following schema:\n",
    "{schema}\n",
    "\n",
    "Respond with 'sql' if the question is related to data retrieval or manipulation that can be expressed in SQL.\n",
    "If the question is related to data visualization, choose one of the following plot types with no explanation: {plot_types}.\n",
    "\"\"\".format(schema=schema, plot_types=\", \".join([member.value for member in PlotType]))\n",
    "    # If the question is related to data visualization, provide the type of plot as one of the following with no explanation: , BAR, LINE, HISTOGRAM, PIE, HEATMAP.\n",
    "    human = f\"Question: {question}\"\n",
    "    check_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", system),\n",
    "            (\"human\", human),\n",
    "        ]\n",
    "    )\n",
    "    llm = ChatOpenAI(temperature=0)\n",
    "    structured_llm = llm.with_structured_output(CheckIfSQLOrPlot)\n",
    "    type_checker = check_prompt | structured_llm\n",
    "    result = type_checker.invoke({})\n",
    "    state[\"meant_as_query\"] = result.meant_as_query == QueryType.SQL\n",
    "    print(\"MEANT AS QUERY: \", state[\"meant_as_query\"])\n",
    "    # if state[\"meant_as_query\"]:\n",
    "    state[\"sql_query_info\"] = SqlQueryInfo(\n",
    "        sql_query=\"\",\n",
    "        query_result=\"\",\n",
    "        table_name=f'transformation_{randint(0, 10000)}',\n",
    "        query_rows=[]\n",
    "    )\n",
    "    # else:\n",
    "    state[\"plot_query_info\"] = PlotQueryInfo(\n",
    "        plot_type=result.type_of_plot.value,\n",
    "        query_result=\"\",\n",
    "        query_rows=[]\n",
    "    )\n",
    "    assert state[\"meant_as_query\"] in [True, False], \"Meant as query should be a boolean\"\n",
    "    print(f\"Determined type: {state['meant_as_query']}\")\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvertToSQL(BaseModel):\n",
    "    sql_query: str = Field(\n",
    "        description=\"The SQL query generated from the natural language question.\"\n",
    "    )\n",
    "\n",
    "def convert_nl_to_sql(state: AgentState, config: RunnableConfig):\n",
    "    print(\"Convert natural language to SQL\")\n",
    "    question = state[\"question\"]\n",
    "    schema = insightly.get_schema()\n",
    "    print(f\"Converting question to SQL: {question}\")\n",
    "    system = \"\"\"You are an assistant that converts natural language questions into SQL queries based on the following schema:\n",
    "database name: {db_name}\n",
    "All tables should begin with the database name (i.e. {db_name}.foods).\n",
    "{schema}\n",
    "\n",
    "Provide only the SQL query without any explanations. Alias columns appropriately to match the expected keys in the result.\n",
    "\n",
    "For example, alias 'food.name' as 'food_name' and 'food.price' as 'price'.\n",
    "\"\"\".format(schema=schema, db_name=insightly.db_name)\n",
    "    convert_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", system),\n",
    "            (\"human\", \"Question: {question}\"),\n",
    "        ]\n",
    "    )\n",
    "    llm = ChatOpenAI(temperature=0)\n",
    "    structured_llm = llm.with_structured_output(ConvertToSQL)\n",
    "    sql_generator = convert_prompt | structured_llm\n",
    "    result = sql_generator.invoke({\"question\": question})\n",
    "    state[\"sql_query_info\"][\"sql_query\"] = result.sql_query\n",
    "    print(f\"Generated SQL query: {state[\"sql_query_info\"]['sql_query']}\")\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_sql(state: AgentState):\n",
    "    sql_query = state[\"sql_query_info\"][\"sql_query\"].strip()\n",
    "    print(f\"Executing SQL query: {sql_query}\")\n",
    "    try:\n",
    "        result: duckdb.DuckDBPyRelation = insightly.execute_query(sql_query)\n",
    "        dataframe = result.df()\n",
    "        state[\"sql_query_info\"][\"query_result\"] = dataframe\n",
    "        print(\"SUCCESSFUL EXECUTION OF SQL QUERY\")\n",
    "        # duckdb add the new df to the database\n",
    "        insightly.add_df_to_duckdb(dataframe, state[\"sql_query_info\"][\"table_name\"])\n",
    "        state[\"sql_query_info\"][\"sql_error\"] = False\n",
    "        # if sql_query.lower().startswith(\"select\"):\n",
    "            \n",
    "        #     print(\"SQL SELECT query executed successfully.\")\n",
    "        # else:\n",
    "        #     state[\"sql_query_info\"][\"query_result\"] = \"The action has been successfully completed.\"\n",
    "        #     state[\"sql_query_info\"][\"sql_error\"] = False\n",
    "        #     print(\"SQL command executed successfully.\")\n",
    "    except Exception as e:\n",
    "        state[\"sql_query_info\"][\"query_result\"] = f\"Error executing SQL query: {str(e)}\"\n",
    "        state[\"sql_query_info\"][\"sql_error\"] = True\n",
    "        print(f\"Error executing SQL query: {str(e)}\")\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "def generate_scatter_plot(df: pd.DataFrame, columns: list[str]):\n",
    "    # columns = state.get(\"columns\", [])\n",
    "    if len(columns) != 2:\n",
    "        raise ValueError(\"Scatter plot requires exactly two columns.\")\n",
    "    \n",
    "    # Generate a scatter plot (this is a placeholder, actual plotting code would go here)\n",
    "    return px.scatter(df, x=columns[0], y=columns[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_bar_plot(df: pd.DataFrame, columns: list[str]):\n",
    "    # columns = state.get(\"columns\", [])\n",
    "    # if len(columns) != 2:\n",
    "    #     raise ValueError(\"Bar plot requires exactly one column.\")\n",
    "    print(\"GENERATE BAR PLOT\")\n",
    "    print(df, type(df))\n",
    "    \n",
    "    # Generate a bar plot (this is a placeholder, actual plotting code would go here)\n",
    "    return px.bar(df, x=columns[0], y=columns[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Columns(BaseModel):\n",
    "    columns: list[str] = Field(\n",
    "        description=\"The columns to be used in the scatter plot.\"\n",
    "    )\n",
    "\n",
    "def get_columns(state: AgentState, config: RunnableConfig):\n",
    "    question = state[\"question\"]\n",
    "    schema = insightly.get_schema(table_name=state['sql_query_info']['table_name'])\n",
    "    print(f\"Getting columns: {question}\")\n",
    "    print(\"current schema: \", schema)\n",
    "    system = \"\"\"You are an assistant that chooses the appropriate columns for a scatter plot based on the following schema:\n",
    "\n",
    "{schema}\n",
    "\n",
    "Provide only the columns to be used in the scatter plot without any explanations.\n",
    "The columns should be suitable for a scatter plot, typically two numerical columns.\n",
    "Only return the names of the columns with no SQL, in the order they should be used in the plot (i.e. x1, y1, x2, y2).\n",
    "\"\"\".format(schema=schema)\n",
    "    convert_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", system),\n",
    "            (\"human\", \"Question: {question}\"),\n",
    "        ]\n",
    "    )\n",
    "    llm = ChatOpenAI(temperature=0)\n",
    "    structured_llm = llm.with_structured_output(Columns)\n",
    "    sql_generator = convert_prompt | structured_llm\n",
    "    result = sql_generator.invoke({\"question\": question})\n",
    "    print(f\"Generated columns for plot: {result.columns}\")\n",
    "    state[\"plot_query_info\"][\"columns\"] = result.columns\n",
    "    # create a plot dependent on the type of plot type passed earlier\n",
    "    if state[\"plot_query_info\"][\"plot_type\"] == PlotType.SCATTER:\n",
    "        state[\"plot_query_info\"][\"result\"] = generate_scatter_plot(state[\"sql_query_info\"][\"query_result\"],\n",
    "                                                                   state[\"plot_query_info\"][\"columns\"])\n",
    "    elif state[\"plot_query_info\"][\"plot_type\"] == PlotType.BAR:\n",
    "        state[\"plot_query_info\"][\"result\"] = generate_bar_plot(state[\"sql_query_info\"][\"query_result\"],\n",
    "                                                               state[\"plot_query_info\"][\"columns\"])\n",
    "    print(f\"Selected columns for scatter plot: {state['plot_query_info']['columns']}\")\n",
    "    return state\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "def generate_funny_response(state: AgentState):\n",
    "    print(\"Generating a funny response for an unrelated question.\")\n",
    "    system = \"\"\"You are a charming and funny assistant who responds in a playful manner.\n",
    "    \"\"\"\n",
    "    human_message = \"I can't help with that unfortunately!\"\n",
    "    funny_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", system),\n",
    "            (\"human\", human_message),\n",
    "        ]\n",
    "    )\n",
    "    llm = ChatOpenAI(temperature=0.7)\n",
    "    funny_response = funny_prompt | llm | StrOutputParser()\n",
    "    message = funny_response.invoke({})\n",
    "    # initialize the SQL query info\n",
    "    state[\"sql_query_info\"] = SqlQueryInfo(\n",
    "        sql_query=\"\",\n",
    "        query_result=\"\",\n",
    "        query_rows=[],\n",
    "        sql_error=False\n",
    "    )\n",
    "    state[\"sql_query_info\"][\"query_result\"] = message\n",
    "    print(\"Generated funny response.\")\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RewrittenQuestion(BaseModel):\n",
    "    question: str = Field(description=\"The rewritten question.\")\n",
    "\n",
    "def regenerate_query(state: AgentState):\n",
    "    question = state[\"question\"]\n",
    "    print(\"Regenerating the SQL query by rewriting the question.\")\n",
    "    system = \"\"\"You are an assistant that reformulates an original question to enable more precise SQL queries. Ensure that all necessary details, such as table joins, are preserved to retrieve complete and accurate data.\n",
    "    \"\"\"\n",
    "    rewrite_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", system),\n",
    "            (\n",
    "                \"human\",\n",
    "                f\"Original Question: {question}\\nReformulate the question to enable more precise SQL queries, ensuring all necessary details are preserved.\",\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "    llm = ChatOpenAI(temperature=0)\n",
    "    structured_llm = llm.with_structured_output(RewrittenQuestion)\n",
    "    rewriter = rewrite_prompt | structured_llm\n",
    "    rewritten = rewriter.invoke({})\n",
    "    state[\"question\"] = rewritten.question\n",
    "    state[\"attempts\"] += 1\n",
    "    print(f\"Rewritten question: {state['question']}\")\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HumanResponse(BaseModel):\n",
    "    response: str = Field(description=\"The human response to the question.\")\n",
    "\n",
    "def human_response(state: AgentState, config: RunnableConfig):\n",
    "    question = state[\"question\"]\n",
    "    answer: str = state[\"sql_query_info\"][\"query_result\"]\n",
    "    print(f\"Waiting for human response to the question: {question}\")\n",
    "    system = \"\"\"You are an assistant that retrieves the result of a question asked\n",
    "by a human and provides a normal response based on the question. The answer is {answer}\"\"\".format(answer=answer)\n",
    "    human_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", system),\n",
    "            (\"human\", f\"Question: {question}\\nPlease provide your response.\"),\n",
    "        ]\n",
    "    )\n",
    "    llm = ChatOpenAI(temperature=0)\n",
    "    structured_llm = llm.with_structured_output(HumanResponse)\n",
    "    human_responder = human_prompt | structured_llm\n",
    "    response = human_responder.invoke({})\n",
    "    state[\"question\"] = response.response\n",
    "    print(f\"Received human response: {state['question']}\")\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "class State(str, Enum):\n",
    "    CHECK_RELEVANCE: str = \"check_relevance\"\n",
    "    CHECK_IF_SQL_OR_PLOT: str = \"check_if_sql_or_plot\"\n",
    "    CONVERT_NL_TO_SQL: str = \"convert_nl_to_sql\"\n",
    "    GET_COLUMNS: str = \"get_columns\"\n",
    "    GENERATE_SCATTER_PLOT: str = \"generate_scatter_plot\"\n",
    "    GENERATE_FUNNY_RESPONSE: str = \"generate_funny_response\"\n",
    "    REGENERATE_QUERY: str = \"regenerate_query\"\n",
    "    EXECUTE_SQL: str = \"execute_sql\"\n",
    "    END_MAX_ITERATIONS: str = \"end_max_iterations\"\n",
    "    CHECK_IF_ERROR: str = \"check_if_error\"\n",
    "    GENERATE_SUCCESS_RESPONSE: str = \"generate_human_response\"\n",
    "\n",
    "# ROUTERS\n",
    "def end_max_iterations(state: AgentState):\n",
    "    state[\"query_result\"] = \"Please try again.\"\n",
    "    print(\"Maximum attempts reached. Ending the workflow.\")\n",
    "    return state\n",
    "\n",
    "def relevance_router(state: AgentState) -> State:\n",
    "    if state[\"relevance\"] == \"relevant\":\n",
    "        return State.CHECK_IF_SQL_OR_PLOT\n",
    "    else:\n",
    "        return State.GENERATE_FUNNY_RESPONSE\n",
    "    \n",
    "def type_router(state: AgentState) -> State:\n",
    "    # NOTE: add a condition to see if it would be more useful to see\n",
    "    # a dataframe instead of a simple English response\n",
    "    if state[\"meant_as_query\"]:\n",
    "        return State.CONVERT_NL_TO_SQL\n",
    "    else:\n",
    "        return State.GET_COLUMNS\n",
    "    \n",
    "def check_if_error(state: AgentState):\n",
    "    if not state.get(\"sql_error\", False):\n",
    "        # if the SQL query was executed, redirect to get columns if looking\n",
    "        # to plot, and to generate a human response if looking to answer\n",
    "        # the question with English\n",
    "        if state[\"meant_as_query\"]:\n",
    "            return State.GENERATE_SUCCESS_RESPONSE\n",
    "        return State.GET_COLUMNS\n",
    "    else:\n",
    "        return State.REGENERATE_QUERY\n",
    "    \n",
    "def check_attempts_router(state: AgentState):\n",
    "    if state[\"attempts\"] < 3:\n",
    "        return State.CONVERT_NL_TO_SQL\n",
    "    else:\n",
    "        return State.END_MAX_ITERATIONS\n",
    "    \n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# relevancy checks at the beginning to ensure question is relevant and can be answered\n",
    "workflow.add_node(State.CHECK_RELEVANCE, check_relevance)\n",
    "workflow.add_node(State.CONVERT_NL_TO_SQL, convert_nl_to_sql)\n",
    "workflow.add_node(State.EXECUTE_SQL, execute_sql)\n",
    "workflow.add_node(State.GENERATE_SUCCESS_RESPONSE, human_response)\n",
    "\n",
    "# if the question is relevant, make a query. If not, generate a funny response\n",
    "workflow.add_conditional_edges(State.CHECK_RELEVANCE, relevance_router)\n",
    "\n",
    "# checking if the question is meant to be answered with SQL statement or a plot\n",
    "workflow.add_node(State.CHECK_IF_SQL_OR_PLOT, check_if_sql_or_plot)\n",
    "workflow.add_edge(State.CHECK_IF_SQL_OR_PLOT, State.CONVERT_NL_TO_SQL)\n",
    "\n",
    "# # adding conditional edge to go different directions based on query type\n",
    "\n",
    "# if the question is meant to be answered with SQL,\n",
    "# convert the natural language question to SQL query\n",
    "workflow.add_edge(State.CONVERT_NL_TO_SQL, State.EXECUTE_SQL)\n",
    "\n",
    "# once SQL has been executed, first check if there was an error\n",
    "workflow.add_conditional_edges(State.EXECUTE_SQL, check_if_error)\n",
    "\n",
    "# regenerate attempt if you still have attempts left -- already errored by this point\n",
    "workflow.add_conditional_edges(State.REGENERATE_QUERY, check_attempts_router)\n",
    "\n",
    "# if the question is relevant but the SQL query is not executed successfully,\n",
    "# regenerate the query by rewriting the question\n",
    "workflow.add_node(State.REGENERATE_QUERY, regenerate_query)\n",
    "workflow.add_edge(State.REGENERATE_QUERY, State.CONVERT_NL_TO_SQL)\n",
    "workflow.add_node(State.END_MAX_ITERATIONS, end_max_iterations)\n",
    "workflow.add_edge(State.END_MAX_ITERATIONS, END)\n",
    "\n",
    "# if the question is meant to be answered with a plot,\n",
    "# get the columns for the scatter plot\n",
    "workflow.add_node(State.GET_COLUMNS, get_columns)\n",
    "# workflow.add_node(State.GENERATE_SCATTER_PLOT, generate_scatter_plot)\n",
    "# workflow.add_edge(State.GET_COLUMNS, State.GENERATE_SCATTER_PLOT)\n",
    "workflow.add_edge(State.GET_COLUMNS, END)\n",
    "\n",
    "# if the question is not relevant, generate a funny response\n",
    "workflow.add_node(State.GENERATE_FUNNY_RESPONSE, generate_funny_response)\n",
    "workflow.add_edge(State.GENERATE_FUNNY_RESPONSE, END)\n",
    "\n",
    "workflow.set_entry_point(State.CHECK_RELEVANCE)\n",
    "\n",
    "app = workflow.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "from langchain_core.runnables.graph import MermaidDrawMethod\n",
    "\n",
    "display(\n",
    "    Image(\n",
    "        app.get_graph().draw_mermaid_png(\n",
    "            draw_method=MermaidDrawMethod.API,\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking relevance of the question: Create a bar plot that shows the number of passengers, grouped by 20 year age buckets.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/patrickwalsh/dev/dataly-backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py:1673: UserWarning: Cannot use method='json_schema' with model gpt-3.5-turbo since it doesn't support OpenAI's Structured Output API. You can see supported models here: https://platform.openai.com/docs/guides/structured-outputs#supported-models. To fix this warning, set `method='function_calling'. Overriding to method='function_calling'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevance determined: relevant\n",
      "Checking if the question requires an SQL query or a plot: Create a bar plot that shows the number of passengers, grouped by 20 year age buckets.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/patrickwalsh/dev/dataly-backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py:1673: UserWarning: Cannot use method='json_schema' with model gpt-3.5-turbo since it doesn't support OpenAI's Structured Output API. You can see supported models here: https://platform.openai.com/docs/guides/structured-outputs#supported-models. To fix this warning, set `method='function_calling'. Overriding to method='function_calling'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEANT AS QUERY:  False\n",
      "Determined type: False\n",
      "Convert natural language to SQL\n",
      "Converting question to SQL: Create a bar plot that shows the number of passengers, grouped by 20 year age buckets.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/patrickwalsh/dev/dataly-backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py:1673: UserWarning: Cannot use method='json_schema' with model gpt-3.5-turbo since it doesn't support OpenAI's Structured Output API. You can see supported models here: https://platform.openai.com/docs/guides/structured-outputs#supported-models. To fix this warning, set `method='function_calling'. Overriding to method='function_calling'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated SQL query: SELECT FLOOR(Age / 20) * 20 AS age_group, COUNT(*) AS num_passengers FROM memory.titanic GROUP BY FLOOR(Age / 20) * 20 ORDER BY age_group\n",
      "Executing SQL query: SELECT FLOOR(Age / 20) * 20 AS age_group, COUNT(*) AS num_passengers FROM memory.titanic GROUP BY FLOOR(Age / 20) * 20 ORDER BY age_group\n",
      "SUCCESSFUL EXECUTION OF SQL QUERY\n",
      "Error executing SQL query: Catalog Error: Table with name dataframe does not exist!\n",
      "Did you mean \"pg_database\"?\n",
      "\n",
      "LINE 1: CREATE TABLE memory.transformation_4504 AS SELECT * FROM dataframe\n",
      "                                                                 ^\n"
     ]
    },
    {
     "ename": "CatalogException",
     "evalue": "Catalog Error: Table with name transformation_4504 does not exist!\nDid you mean \"titanic\"?",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mCatalogException\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m question = \u001b[33m\"\u001b[39m\u001b[33mCreate a bar plot that shows the number of passengers, grouped by 20 year age buckets.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m result: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]] = \u001b[43mapp\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mquestion\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mattempts\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m result.get(\u001b[33m\"\u001b[39m\u001b[33mmeant_as_query\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m      4\u001b[39m     \u001b[38;5;66;03m# if the SQL query was executed successfully, print the result\u001b[39;00m\n\u001b[32m      5\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mResult:\u001b[39m\u001b[33m\"\u001b[39m, result[\u001b[33m\"\u001b[39m\u001b[33msql_query_info\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mquery_result\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/dataly-backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py:2795\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, **kwargs)\u001b[39m\n\u001b[32m   2793\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2794\u001b[39m     chunks = []\n\u001b[32m-> \u001b[39m\u001b[32m2795\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2796\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2799\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2800\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2801\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2802\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcheckpoint_during\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheckpoint_during\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2803\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2804\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2805\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2806\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   2807\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlatest\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/dataly-backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py:2433\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[39m\n\u001b[32m   2427\u001b[39m     \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[32m   2428\u001b[39m     \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates.\u001b[39;00m\n\u001b[32m   2429\u001b[39m     \u001b[38;5;66;03m# Channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[32m   2430\u001b[39m     \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[32m   2431\u001b[39m     \u001b[38;5;66;03m# with channel updates applied only at the transition between steps.\u001b[39;00m\n\u001b[32m   2432\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m loop.tick(input_keys=\u001b[38;5;28mself\u001b[39m.input_channels):\n\u001b[32m-> \u001b[39m\u001b[32m2433\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2434\u001b[39m \u001b[43m            \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2435\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2436\u001b[39m \u001b[43m            \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2437\u001b[39m \u001b[43m            \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2438\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2439\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2440\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2441\u001b[39m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 8\u001b[39m, in \u001b[36mget_columns\u001b[39m\u001b[34m(state, config)\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_columns\u001b[39m(state: AgentState, config: RunnableConfig):\n\u001b[32m      7\u001b[39m     question = state[\u001b[33m\"\u001b[39m\u001b[33mquestion\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     schema = \u001b[43minsightly\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtable_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msql_query_info\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtable_name\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mGetting columns: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquestion\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     10\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mcurrent schema: \u001b[39m\u001b[33m\"\u001b[39m, schema)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 124\u001b[39m, in \u001b[36mInsightly.get_schema\u001b[39m\u001b[34m(self, table_name)\u001b[39m\n\u001b[32m    120\u001b[39m schemas = {}\n\u001b[32m    122\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m table \u001b[38;5;129;01min\u001b[39;00m tables:\n\u001b[32m    123\u001b[39m     \u001b[38;5;66;03m# Fetch column info\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m     info = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mPRAGMA table_info(\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdb_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m.\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mtable\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m'\u001b[39;49m\u001b[33;43m)\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m.fetchall()\n\u001b[32m    126\u001b[39m     \u001b[38;5;66;03m# Format into a string\u001b[39;00m\n\u001b[32m    127\u001b[39m     schema_string = \u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol[\u001b[32m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol[\u001b[32m2\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m info)\n",
      "\u001b[31mCatalogException\u001b[39m: Catalog Error: Table with name transformation_4504 does not exist!\nDid you mean \"titanic\"?",
      "During task with name 'State.GET_COLUMNS' and id '164bea38-5507-10bd-875b-90668843e9d1'"
     ]
    }
   ],
   "source": [
    "question = \"Create a bar plot that shows the number of passengers, grouped by 20 year age buckets.\"\n",
    "result: dict[str, dict[str, Any]] = app.invoke({\"question\": question, \"attempts\": 0}, config={})\n",
    "if result.get(\"meant_as_query\", False):\n",
    "    # if the SQL query was executed successfully, print the result\n",
    "    print(\"Result:\", result[\"sql_query_info\"][\"query_result\"])\n",
    "else:\n",
    "    # if the plot was generated successfully, show the plot that was returned\n",
    "    result[\"plot_query_info\"][\"result\"].show()\n",
    "# else:\n",
    "#     print(result)\n",
    "#     print(\"Something went wrong along the way! Try again.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table name: titanic\n",
      "PassengerId BIGINT, Survived BIGINT, Pclass BIGINT, Name VARCHAR, Sex VARCHAR, Age DOUBLE, SibSp BIGINT, Parch BIGINT, Ticket VARCHAR, Fare DOUBLE, Cabin VARCHAR, Embarked VARCHAR\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(insightly.get_schema())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
